# -*- coding: utf-8 -*-
"""Instagram Reach Forecasting.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZR6r9VhN2sbkr6B5KcLp0nb9-8qSEHtG
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from google.colab import files

uploaded = files.upload()

df = pd.read_csv('Instagram-Reach.csv')
df.head()

df.head()

df.dtypes

df= pd.read_csv('Instagram-Reach.csv', parse_dates= ["Date"] , index_col= "Date")

df.head()

df.dtypes

#method is used to select rows and columns from dataframe
df.loc["2022-04-04"]

# to make plots more professional and consistent
from pylab import rcParams
rcParams['figure.figsize'] =10,7
df.plot()
plt.ylabel('Instagram Reach', color='purple')
plt.xlabel('Date', color='blue')
plt.show()

#decomposing time series multiplicatively
#used for statistical data
from statsmodels.tsa.seasonal import seasonal_decompose
df_mul_decom= seasonal_decompose(df, model= "multiplicative")
df_mul_decom.plot()
plt.show()

# train test split
train= df.loc[df.index < '12-01-2022']
test= df.loc[df.index >= '12-01-2022']
fig, ax= plt.subplots(figsize= (15,5))
train.plot(ax=ax, label= 'trainingset')
test.plot(ax=ax, label= 'testingset')

df.index.dayofweek

#feature selection
def create_feature(df):
  df['dayofweek'] = df.index.dayofweek
  df['quarter'] = df.index.quarter
  df['month'] = df.index.month
  df['dayofyear'] = df.index.dayofyear
  return df

df = create_feature(df)
print(df)

#this is ml algo library for both regression and classification task as it is fast and gives accurate results
import xgboost as xgb
from sklearn.metrics import mean_squared_error

train = create_feature(train)
test = create_feature(test)

df.columns

#regression model
target= ['Instagram reach']
features= ['dayofweek', 'quarter', 'month', 'dayofyear']
x_train= train[features]
y_train= train[target]
x_test= test[features]
y_test= test[target]

#calling regression function and fitting of data side by side validation of training and testing set
reg= xgb.XGBRegressor(n_estimators = 1000, early_stopping_rounds = 50)
reg.fit(x_train, y_train,
      eval_set=[(x_train, y_train), (x_test, y_test)],
        verbose=100)

#importance wise arrange hoin
pd.DataFrame(reg.feature_importances_,
             index=reg.feature_names_in_,
             columns=['importance'])

#pip install fi

reg.predict(x_test)

test['prediction'] = reg.predict(x_test)

df = df.merge(test[['prediction']], how='left',left_index = True, right_index = True)
df

ax = df[['Instagram reach']].plot(figsize=(15,5), color='red')
df['prediction'].plot(ax=ax , style='.')
ax.set_title("Instagram data and Prediction")
plt.show()

# prediction for one week
ax = df.loc[(df.index > '12-01-2022') & (df.index < '12-08-2022')]['Instagram reach'].plot(figsize = (15,5), title='Week of Data', color='purple')
df.loc[(df.index > '12-01-2022') & (df.index < '12-08-2022')]['prediction'].plot(style='*', color='green' )
plt.show()

